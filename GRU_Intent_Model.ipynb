{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CIS 583 Term Project - Coffee Chain Chatbot\n",
        "# LSTM + Transformer + GRU\n",
        "# ============================================\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "def load_sales_data(file_path):\n",
        "    \"\"\"\n",
        "    Loads a sales DataFrame from a CSV file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found.\")\n",
        "        return None\n",
        "\n",
        "df_sales = load_sales_data(\"/content/Coffee_Chain_Sales .csv\")\n",
        "\n",
        "if df_sales is None:\n",
        "    # Exit if the file wasn't found.\n",
        "    raise SystemExit(\"Exiting due to missing data file.\")\n",
        "\n",
        "print(\"Loaded Sales Data:\")\n",
        "print(df_sales.head())\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df_sales.info()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SalesChatbot:\n",
        "    \"\"\"\n",
        "    A simple rule-based chatbot for sales analytics queries\n",
        "    based on the coffee chain data.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_frame):\n",
        "        self.df = data_frame\n",
        "        self.greetings = [\n",
        "            \"Hello! How can I help you with sales analytics today?\",\n",
        "            \"Hi there! I'm ready to answer your sales questions.\",\n",
        "            \"Welcome! What sales data can I analyze for you?\"\n",
        "        ]\n",
        "        self.default_responses = [\n",
        "            \"I'm not sure I understand that query. Can you please rephrase it?\",\n",
        "            \"Sorry, I can't process that request right now.\",\n",
        "            \"I need more information to answer that question.\"\n",
        "        ]\n",
        "\n",
        "    def get_greeting(self):\n",
        "        \"\"\"Returns a random greeting.\"\"\"\n",
        "        return random.choice(self.greetings)\n",
        "\n",
        "    def get_response(self, query):\n",
        "        \"\"\"\n",
        "        Processes a user query and returns a response based on keywords.\n",
        "        (Purely rule-based, no ML here.)\n",
        "        \"\"\"\n",
        "        query_lower = query.lower()\n",
        "\n",
        "        if 'total sales' in query_lower or 'total revenue' in query_lower:\n",
        "            return self.get_total_sales()\n",
        "        elif 'best selling' in query_lower or 'most popular' in query_lower:\n",
        "            return self.get_best_selling_product()\n",
        "        elif 'sales by region' in query_lower or 'region sales' in query_lower:\n",
        "            return self.get_sales_by_market()\n",
        "        elif 'sales for' in query_lower:\n",
        "            match = re.search(r'sales for (\\w+)', query_lower)\n",
        "            if match:\n",
        "                product = match.group(1).capitalize()\n",
        "                return self.get_sales_for_product(product)\n",
        "            else:\n",
        "                return \"Please specify a product name, e.g., 'sales for Espresso'.\"\n",
        "        else:\n",
        "            return random.choice(self.default_responses)\n",
        "\n",
        "    def get_total_sales(self):\n",
        "        \"\"\"Calculates and returns the total sales from the 'Sales' column.\"\"\"\n",
        "        total_sales = self.df['Sales'].sum()\n",
        "        return f\"The total sales for the period is: ${total_sales:,.2f}\"\n",
        "\n",
        "    def get_best_selling_product(self):\n",
        "        \"\"\"Identifies and returns the best-selling product based on total sales.\"\"\"\n",
        "        best_product = self.df.groupby('Product')['Sales'].sum().idxmax()\n",
        "        return f\"The best-selling product is: {best_product}.\"\n",
        "\n",
        "    def get_sales_by_market(self):\n",
        "        \"\"\"Calculates and returns sales data by market from the 'Market' column.\"\"\"\n",
        "        regional_sales = (\n",
        "            self.df.groupby('Market')['Sales']\n",
        "            .sum()\n",
        "            .sort_values(ascending=False)\n",
        "        )\n",
        "        response = \"Total sales by market:\\n\"\n",
        "        for region, sales in regional_sales.items():\n",
        "            response += f\"- {region}: ${sales:,.2f}\\n\"\n",
        "        return response.strip()\n",
        "\n",
        "    def get_sales_for_product(self, product):\n",
        "        \"\"\"Calculates and returns total sales for a specific product.\"\"\"\n",
        "        product_sales = self.df[self.df['Product'].str.lower() == product.lower()]['Sales'].sum()\n",
        "        if product_sales > 0:\n",
        "            return f\"The total sales for {product} is: ${product_sales:,.2f}\"\n",
        "        else:\n",
        "            return f\"No sales data found for the product '{product}'.\"\n",
        "\n",
        "\n",
        "\n",
        "queries = [\n",
        "    \"What is the total sales?\",\n",
        "    \"Show me the sales by market.\",\n",
        "    \"Which product is the best-selling?\",\n",
        "    \"Show me sales for the Caffe Mocha.\",\n",
        "    \"Tell me about the total revenue.\",\n",
        "    \"What are the sales by region?\",\n",
        "    \"How much was sold for espresso?\",\n",
        "    \"What's the best product?\"\n",
        "]\n",
        "\n",
        "# Intent IDs: 0, 1, 2, 3\n",
        "intents = [0, 1, 2, 3, 0, 1, 3, 2]\n",
        "intent_map = {\n",
        "    0: \"total_sales\",\n",
        "    1: \"sales_by_market\",\n",
        "    2: \"best_selling_product\",\n",
        "    3: \"sales_for_product\"\n",
        "}\n",
        "\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(queries)\n",
        "sequences = tokenizer.texts_to_sequences(queries)\n",
        "padded_sequences = keras.preprocessing.sequence.pad_sequences(sequences, padding='post')\n",
        "labels = np.array(intents)\n",
        "\n",
        "print(\"\\n--- NLP Model Data Preparation ---\")\n",
        "print(\"Padded Sequences:\")\n",
        "print(padded_sequences)\n",
        "print(\"Labels:\")\n",
        "print(labels)\n",
        "\n",
        "\n",
        "# Build the LSTM model\n",
        "def build_lstm_model(input_shape, vocab_size, embedding_dim, num_classes):\n",
        "    \"\"\"Builds a simple LSTM model for intent classification.\"\"\"\n",
        "    inputs = Input(shape=(input_shape,))\n",
        "    x = Embedding(vocab_size, embedding_dim)(inputs)\n",
        "    x = LSTM(128, return_sequences=False)(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=\"LSTM_Model\")\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Build the Transformer model\n",
        "def build_transformer_model(input_shape, vocab_size, embedding_dim, num_classes, head_size, num_heads):\n",
        "    \"\"\"Builds a simple Transformer model for intent classification.\"\"\"\n",
        "    def transformer_encoder(inputs, head_size, num_heads):\n",
        "        x = keras.layers.MultiHeadAttention(\n",
        "            key_dim=head_size, num_heads=num_heads, dropout=0.5\n",
        "        )(inputs, inputs)\n",
        "        x = keras.layers.Dropout(0.5)(x)\n",
        "        x = keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        res = x + inputs\n",
        "\n",
        "        x = keras.layers.Dense(head_size * 2, activation=\"relu\")(res)\n",
        "        x = keras.layers.Dropout(0.5)(x)\n",
        "        x = keras.layers.Dense(inputs.shape[-1])(x)\n",
        "        x = keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        return x + res\n",
        "\n",
        "    inputs = Input(shape=(input_shape,))\n",
        "    x = Embedding(vocab_size, embedding_dim)(inputs)\n",
        "    x = transformer_encoder(x, head_size=head_size, num_heads=num_heads)\n",
        "    x = keras.layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=\"Transformer_Model\")\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "max_sequence_length = padded_sequences.shape[1]\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 64\n",
        "num_classes = len(np.unique(labels))\n",
        "head_size = 128\n",
        "num_heads = 2\n",
        "\n",
        "# Build and train the LSTM model\n",
        "print(\"\\n--- Training the LSTM Model ---\")\n",
        "lstm_model = build_lstm_model(max_sequence_length, vocab_size, embedding_dim, num_classes)\n",
        "lstm_history = lstm_model.fit(\n",
        "    padded_sequences, labels,\n",
        "    epochs=10,\n",
        "    verbose=0\n",
        ")\n",
        "print(\"LSTM Model training finished.\")\n",
        "\n",
        "# Build and train the Transformer model\n",
        "print(\"\\n--- Training the Transformer Model ---\")\n",
        "transformer_model = build_transformer_model(\n",
        "    max_sequence_length, vocab_size, embedding_dim, num_classes, head_size, num_heads\n",
        ")\n",
        "transformer_history = transformer_model.fit(\n",
        "    padded_sequences, labels,\n",
        "    epochs=10,\n",
        "    verbose=0\n",
        ")\n",
        "print(\"Transformer Model training finished.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict_intent(model, query):\n",
        "    \"\"\"Predicts the intent of a user query using a given model.\"\"\"\n",
        "    new_sequence = tokenizer.texts_to_sequences([query])\n",
        "    new_padded_sequence = keras.preprocessing.sequence.pad_sequences(\n",
        "        new_sequence, maxlen=max_sequence_length, padding='post'\n",
        "    )\n",
        "    prediction = model.predict(new_padded_sequence, verbose=0)[0]\n",
        "    predicted_intent = np.argmax(prediction)\n",
        "    predicted_intent_name = intent_map.get(predicted_intent, \"unknown_intent\")\n",
        "    return predicted_intent_name\n",
        "\n",
        "print(\"\\n--- Demonstrating NLP Model Prediction ---\")\n",
        "test_query = \"What is the total revenue?\"\n",
        "predicted_intent_lstm = predict_intent(lstm_model, test_query)\n",
        "print(f\"User query: '{test_query}'\")\n",
        "print(f\"LSTM model predicts intent: '{predicted_intent_lstm}'\")\n",
        "\n",
        "test_query_2 = \"What are the sales for espresso?\"\n",
        "predicted_intent_trans = predict_intent(transformer_model, test_query_2)\n",
        "print(f\"User query: '{test_query_2}'\")\n",
        "print(f\"Transformer model predicts intent: '{predicted_intent_trans}'\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n===  GRU INTENT MODEL ===\")\n",
        "\n",
        "def build_gru_model(input_length, vocab_size, embedding_dim, num_classes):\n",
        "    \"\"\"\n",
        "    GRU-based neural network for intent classification.\n",
        "\n",
        "    \"\"\"\n",
        "    inputs = Input(shape=(input_length,))\n",
        "    x = Embedding(vocab_size, embedding_dim)(inputs)\n",
        "    x = GRU(128, return_sequences=False)(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=\"GRU_Intent_Model\")\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "gru_model = build_gru_model(\n",
        "    input_length=max_sequence_length,\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    num_classes=num_classes\n",
        ")\n",
        "\n",
        "gru_history = gru_model.fit(\n",
        "    padded_sequences,\n",
        "    labels,\n",
        "    epochs=15,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\" Finished training GRU model.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict_intent_gru(model, query):\n",
        "    \"\"\"\n",
        "    Use Germaine's GRU model to predict the intent of a query.\n",
        "    Returns an intent name like 'total_sales', 'sales_by_market', etc.\n",
        "    \"\"\"\n",
        "    seq = tokenizer.texts_to_sequences([query])\n",
        "    pad = keras.preprocessing.sequence.pad_sequences(\n",
        "        seq, maxlen=max_sequence_length, padding='post'\n",
        "    )\n",
        "    probs = model.predict(pad, verbose=0)[0]\n",
        "    pred_id = int(np.argmax(probs))\n",
        "    return intent_map.get(pred_id, \"unknown_intent\")\n",
        "\n",
        "test_queries = [\n",
        "    \"What is the total revenue?\",\n",
        "    \"Show me the sales by region.\",\n",
        "    \"Which product sells the most?\",\n",
        "    \"What are the sales for espresso?\"\n",
        "]\n",
        "\n",
        "print(\"\\n--- GRU Model Predictions (Germaine) ---\")\n",
        "for q in test_queries:\n",
        "    print(q, \"->\", predict_intent_gru(gru_model, q))\n",
        "\n",
        "\n",
        "\n",
        "class GRUSalesAssistant:\n",
        "    \"\"\"\n",
        "    Chatbot that uses:\n",
        "    - Germaine's GRU model to classify intent\n",
        "    - SalesChatbot to compute actual answers from df_sales\n",
        "    \"\"\"\n",
        "    def __init__(self, data_frame, model):\n",
        "        self.model = model\n",
        "        self.rule_bot = SalesChatbot(data_frame)\n",
        "\n",
        "    def get_response(self, query):\n",
        "        intent_name = predict_intent_gru(self.model, query)\n",
        "\n",
        "        if intent_name == \"total_sales\":\n",
        "            return self.rule_bot.get_total_sales()\n",
        "        elif intent_name == \"best_selling_product\":\n",
        "            return self.rule_bot.get_best_selling_product()\n",
        "        elif intent_name == \"sales_by_market\":\n",
        "            return self.rule_bot.get_sales_by_market()\n",
        "        elif intent_name == \"sales_for_product\":\n",
        "            # try to extract product name\n",
        "            match = re.search(r'sales for (.+)', query.lower())\n",
        "            if match:\n",
        "                product = match.group(1).strip().title()\n",
        "                return self.rule_bot.get_sales_for_product(product)\n",
        "            else:\n",
        "                return \"I think you're asking about sales for a product, but I couldn't detect the product name. Try 'sales for Espresso'.\"\n",
        "        else:\n",
        "            # fallback: use original rule-based chatbot\n",
        "            return self.rule_bot.get_response(query)\n",
        "\n",
        "gru_assistant = GRUSalesAssistant(df_sales, gru_model)\n",
        "\n",
        "print(\"\\n=== GRU Sales Assistant Demo (Germaine) ===\")\n",
        "for q in test_queries:\n",
        "    print(\"\\nYou:\", q)\n",
        "    print(\"Bot:\", gru_assistant.get_response(q))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"= Running Rule-Based Chatbot Simulation =\")\n",
        "    print(\"=\"*50)\n",
        "    bot = SalesChatbot(df_sales)\n",
        "    print(bot.get_greeting())\n",
        "    print(\"\\nTry asking me things like:\")\n",
        "    print(\"- 'What is the total sales?'\")\n",
        "    print(\"- 'What is the best selling product?'\")\n",
        "    print(\"- 'Show me sales by market.'\")\n",
        "    print(\"- 'What are the sales for Decaf?'\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"You: \")\n",
        "        if user_query.lower() in ['exit', 'quit', 'bye']:\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        response = bot.get_response(user_query)\n",
        "        print(\"Chatbot:\", response)\n"
      ],
      "metadata": {
        "id": "DkJDOxe1TBni"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}