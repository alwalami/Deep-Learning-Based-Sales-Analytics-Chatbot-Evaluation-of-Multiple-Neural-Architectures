{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fb145c04",
      "metadata": {
        "id": "fb145c04"
      },
      "source": [
        "# CIS 583 Term Project ‚Äì OrderBot with Two LLM Architectures\n",
        "\n",
        "This notebook implements a pizza-ordering chatbot (OrderBot) using **two local GGUF LLMs**\n",
        "via `llama-cpp-python`. It is designed so you can compare the behavior of two different\n",
        "architectures (e.g., Llama 2 and Mistral)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58176f62",
      "metadata": {
        "id": "58176f62"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install llama-cpp-python huggingface_hub panel jupyter_bokeh pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6242e41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263,
          "referenced_widgets": [
            "fdf9dbee54d54eb3bc0350524505752a",
            "99b79a9f6acd4f53ac1d2c07d8522fc3",
            "117075ac4e0343158afd7c4a354558e3",
            "49ae8a83d76743999e220d6cb3f47cb7",
            "7b6d7ad13ffd443a92129b6b6dae6fab",
            "045f229853ff428b9188c47de072402f",
            "8f8f97f82ced4c5eb40fa53f8f20448f",
            "814f847baee74880a6e03076b7a3a845",
            "86cbee431aee469d8ad65f22fd276426",
            "2b2c5d4440324412ad2f69855f238086",
            "c096bcd5ac904577a91ebad1ccaa8297",
            "06d65da0cdbd4d47b351d2557d769353",
            "ed4e8e8fd2874f79ae72829f3d55734d",
            "f38200bb13454941ae984901ef0f8b2d",
            "758161cdcb7c4ab083ee827bcae71b6e",
            "ff8b5507f0594ae9a4b5101d6efdcd62",
            "ff9472ae86a5423f9276c4a0d1337ef0",
            "f0eeb4d361c74d32b52370eef593461d",
            "8026efa8cd3341aabb2a0d0eca997630",
            "52db477f1d924817b5367928014c434e",
            "aed38117fad94062b75a785338446c8a",
            "4c9a8b1d4a75418c9dbeddc080157ea5"
          ]
        },
        "id": "c6242e41",
        "outputId": "16aa1ba8-a813-42b8-a890-49866331067d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Downloading TheBloke/Llama-2-7B-Chat-GGUF/llama-2-7b-chat.Q4_K_M.gguf ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdf9dbee54d54eb3bc0350524505752a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "llama-2-7b-chat.Q4_K_M.gguf:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Downloaded to: models/llama-2-7b-chat.Q4_K_M.gguf\n",
            " Downloading TheBloke/Mistral-7B-Instruct-v0.2-GGUF/mistral-7b-instruct-v0.2.Q4_K_M.gguf ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06d65da0cdbd4d47b351d2557d769353",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "mistral-7b-instruct-v0.2.Q4_K_M.gguf:   0%|          | 0.00/4.37G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Downloaded to: models/mistral-7b-instruct-v0.2.Q4_K_M.gguf\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "MODEL_A_REPO_ID = 'TheBloke/Llama-2-7B-Chat-GGUF'\n",
        "MODEL_A_FILENAME = 'llama-2-7b-chat.Q4_K_M.gguf'\n",
        "\n",
        "MODEL_B_REPO_ID = 'TheBloke/Mistral-7B-Instruct-v0.2-GGUF'\n",
        "MODEL_B_FILENAME = 'mistral-7b-instruct-v0.2.Q4_K_M.gguf'\n",
        "\n",
        "def download_model(repo_id, filename):\n",
        "    local_path = os.path.join('models', filename)\n",
        "    if os.path.exists(local_path):\n",
        "        print(' Using existing local model:', local_path)\n",
        "        return local_path\n",
        "\n",
        "    print(f' Downloading {repo_id}/{filename} ...')\n",
        "    path = hf_hub_download(\n",
        "        repo_id=repo_id,\n",
        "        filename=filename,\n",
        "        local_dir='models',\n",
        "        local_dir_use_symlinks=False,\n",
        "    )\n",
        "    print(' Downloaded to:', path)\n",
        "    return path\n",
        "\n",
        "model_a_path = download_model(MODEL_A_REPO_ID, MODEL_A_FILENAME)\n",
        "model_b_path = download_model(MODEL_B_REPO_ID, MODEL_B_FILENAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a59b6b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a59b6b6",
        "outputId": "0b15d89d-e34a-471d-d503-1a0a362482ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_context: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Backends ready: Llama-2-7B-Chat and Mistral-7B-Instruct-v0.2\n"
          ]
        }
      ],
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "class LlamaChat:\n",
        "    def __init__(self, model_path: str, name: str):\n",
        "        self.name = name\n",
        "        self.llm = Llama(\n",
        "            model_path=model_path,\n",
        "            n_ctx=4096,\n",
        "            n_gpu_layers=0,\n",
        "            verbose=False,\n",
        "        )\n",
        "\n",
        "    def chat(self, messages):\n",
        "        \"\"\"messages is a list of {role, content} dicts (OpenAI-style).\"\"\"\n",
        "        result = self.llm.create_chat_completion(messages=messages)\n",
        "        return result['choices'][0]['message']['content']\n",
        "\n",
        "llm_a = LlamaChat(model_a_path, name='Llama-2-7B-Chat')\n",
        "llm_b = LlamaChat(model_b_path, name='Mistral-7B-Instruct-v0.2')\n",
        "\n",
        "print('Backends ready:', llm_a.name, 'and', llm_b.name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7d0ca9a",
      "metadata": {
        "id": "a7d0ca9a"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = '''\\\n",
        "You are OrderBot, an automated service for XYZ Pizza.\n",
        "\n",
        "Your goals:\n",
        "1. Greet the customer politely.\n",
        "2. Ask for the customer's name.\n",
        "3. Collect the full pizza order:\n",
        "   - pizza type\n",
        "   - size\n",
        "   - quantity\n",
        "   - extras/toppings\n",
        "4. Ask if the order is pickup or delivery.\n",
        "   - If delivery: ask for address and phone number.\n",
        "5. Confirm the complete order back to the customer.\n",
        "6. Provide an itemized price, tax, and total.\n",
        "7. Ask if they want to change anything before finalizing.\n",
        "\n",
        "Stay focused on the pizza order. Be friendly and concise.\n",
        "'''\n",
        "\n",
        "def make_initial_context():\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"assistant\", \"content\": \"Hello! Welcome to XYZ Pizza. What is your name?\"},\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d7f7318",
      "metadata": {
        "id": "7d7f7318"
      },
      "outputs": [],
      "source": [
        "test_scenarios = [\n",
        "    {\n",
        "        'name': 'simple_one_pizza',\n",
        "        'user_turns': [\n",
        "            'Hi, my name is Osamah.',\n",
        "            'I want one large pepperoni pizza.',\n",
        "            'Delivery please.',\n",
        "            'My address is 123 Main Street and my phone is 555-0000.',\n",
        "            'Yes, that is everything.'\n",
        "        ],\n",
        "        'expected_slots': {\n",
        "            'name': 'Osamah',\n",
        "            'items': [('pepperoni pizza', 'large', 1)],\n",
        "            'delivery_or_pickup': 'delivery',\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        'name': 'multiple_pizzas',\n",
        "        'user_turns': [\n",
        "            \"Hello, I'm Sara.\",\n",
        "            'I want two medium cheese pizzas and one small veggie pizza.',\n",
        "            'Pickup.',\n",
        "            'Yes, that is correct.'\n",
        "        ],\n",
        "        'expected_slots': {\n",
        "            'name': 'Sara',\n",
        "            'items': [\n",
        "                ('cheese pizza', 'medium', 2),\n",
        "                ('veggie pizza', 'small', 1),\n",
        "            ],\n",
        "            'delivery_or_pickup': 'pickup',\n",
        "        },\n",
        "    },\n",
        "\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d333d0f9",
      "metadata": {
        "id": "d333d0f9"
      },
      "outputs": [],
      "source": [
        "def run_scenario(llm: LlamaChat, scenario):\n",
        "    messages = make_initial_context()\n",
        "    transcript = []\n",
        "\n",
        "    for user_msg in scenario['user_turns']:\n",
        "        messages.append({'role': 'user', 'content': user_msg})\n",
        "        assistant_reply = llm.chat(messages)\n",
        "        messages.append({'role': 'assistant', 'content': assistant_reply})\n",
        "\n",
        "        transcript.append({\n",
        "            'user': user_msg,\n",
        "            'assistant': assistant_reply,\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        'model': llm.name,\n",
        "        'scenario': scenario['name'],\n",
        "        'transcript': transcript,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4edef8ac",
      "metadata": {
        "id": "4edef8ac"
      },
      "outputs": [],
      "source": [
        "def score_transcript(result, scenario):\n",
        "    text = ' '.join(t['assistant'] for t in result['transcript']).lower()\n",
        "    score = 0\n",
        "    max_score = 3\n",
        "\n",
        "    if scenario['expected_slots']['name'].lower() in text:\n",
        "        score += 1\n",
        "\n",
        "    all_items_ok = True\n",
        "    for (ptype, size, qty) in scenario['expected_slots']['items']:\n",
        "        if ptype.lower() not in text or size.lower() not in text:\n",
        "            all_items_ok = False\n",
        "            break\n",
        "    if all_items_ok:\n",
        "        score += 1\n",
        "\n",
        "    mode = scenario['expected_slots']['delivery_or_pickup'].lower()\n",
        "    if mode in text:\n",
        "        score += 1\n",
        "\n",
        "    return score, max_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3cc2644",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d3cc2644",
        "outputId": "928ec5b3-767d-4e69-c410-17d6eda543a0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"scenario\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"multiple_pizzas\",\n          \"simple_one_pizza\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Llama-2-7B-Chat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Mistral-7B-Instruct-v0.2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_a\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_results"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8c3ecfd5-3d5f-47bc-a66b-19a59d8e9ad9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scenario</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>score_a</th>\n",
              "      <th>score_b</th>\n",
              "      <th>max_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>simple_one_pizza</td>\n",
              "      <td>Llama-2-7B-Chat</td>\n",
              "      <td>Mistral-7B-Instruct-v0.2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>multiple_pizzas</td>\n",
              "      <td>Llama-2-7B-Chat</td>\n",
              "      <td>Mistral-7B-Instruct-v0.2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c3ecfd5-3d5f-47bc-a66b-19a59d8e9ad9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c3ecfd5-3d5f-47bc-a66b-19a59d8e9ad9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c3ecfd5-3d5f-47bc-a66b-19a59d8e9ad9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3e0bcebd-92bc-485d-b4fb-2cfc88980e4b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3e0bcebd-92bc-485d-b4fb-2cfc88980e4b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3e0bcebd-92bc-485d-b4fb-2cfc88980e4b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_2262c454-556b-4729-be67-6231d93d4f55\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2262c454-556b-4729-be67-6231d93d4f55 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           scenario          model_a                   model_b  score_a  \\\n",
              "0  simple_one_pizza  Llama-2-7B-Chat  Mistral-7B-Instruct-v0.2        3   \n",
              "1   multiple_pizzas  Llama-2-7B-Chat  Mistral-7B-Instruct-v0.2        3   \n",
              "\n",
              "   score_b  max_score  \n",
              "0        3          3  \n",
              "1        2          3  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for scenario in test_scenarios:\n",
        "    # Model A\n",
        "    res_a = run_scenario(llm_a, scenario)\n",
        "    score_a, max_s = score_transcript(res_a, scenario)\n",
        "\n",
        "    # Model B\n",
        "    res_b = run_scenario(llm_b, scenario)\n",
        "    score_b, _ = score_transcript(res_b, scenario)\n",
        "\n",
        "    all_results.append({\n",
        "        'scenario': scenario['name'],\n",
        "        'model_a': llm_a.name,\n",
        "        'model_b': llm_b.name,\n",
        "        'score_a': score_a,\n",
        "        'score_b': score_b,\n",
        "        'max_score': max_s,\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(all_results)\n",
        "df_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a658cecb",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a658cecb",
        "outputId": "47946293-adbe-4e45-de74-650764492c57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USER: Hi, my name is Osamah.\n",
            "BOT :   Great, Osamah! Thank you for ordering from XYZ Pizza. Can you please tell me what type of pizza you would like to order? We have a variety of options on our menu, such as Pepperoni, Margherita, Meat Lover's, and more. Please let me know the size and quantity you would like, as well as any extra toppings you would like to add.\n",
            "----------------------------------------\n",
            "USER: I want one large pepperoni pizza.\n",
            "BOT :   Great choice, Osamah! One large Pepperoni Pizza coming right up. Would you like to pick up your order or have it delivered? If delivery, could you please provide me with your address and phone number?\n",
            "----------------------------------------\n",
            "USER: Delivery please.\n",
            "BOT :   Great, thank you! I will confirm your order and provide you with an estimated delivery time. Your order will be delivered to your address within the estimated time frame. Is there anything else I can assist you with?\n",
            "----------------------------------------\n",
            "USER: My address is 123 Main Street and my phone is 555-0000.\n",
            "BOT :   Great, thank you for providing your address and phone number. I have noted them down. Your order for one large Pepperoni Pizza will be delivered to 123 Main Street within the estimated delivery time frame. Please let me know if you have any other questions or concerns. Is there anything else I can assist you with?\n",
            "----------------------------------------\n",
            "USER: Yes, that is everything.\n",
            "BOT :   Great, thank you for confirming. Your order is now confirmed and will be delivered to your address within the estimated delivery time frame. Your total comes out to be $23.99, including tax. Is there anything else I can assist you with?\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Example: print transcript for first scenario using Model A\n",
        "example_res_a = run_scenario(llm_a, test_scenarios[0])\n",
        "for turn in example_res_a['transcript']:\n",
        "    print('USER:', turn['user'])\n",
        "    print('BOT :', turn['assistant'])\n",
        "    print('-' * 40)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G5h5abGZ-FMU",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G5h5abGZ-FMU",
        "outputId": "ef45b882-165d-4cd8-e262-1f6dd3c2f631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USER: Hi, my name is Osamah.\n",
            "BOT :  Hi Osamah! It's nice to meet you. How can I help you today at XYZ Pizza? Would you like to order a pizza for delivery or pick-up? We have a variety of delicious pizzas to choose from, as well as sides and desserts. Let me know if you have any dietary restrictions or preferences, and I'll be happy to help you find something that suits your needs. If you're not quite ready to order yet, feel free to browse our menu on our website or ask me any questions you might have. I'm here to make your experience at XYZ Pizza as enjoyable as possible!\n",
            "----------------------------------------\n",
            "USER: I want one large pepperoni pizza.\n",
            "BOT :  Great choice, Osamah! A large pepperoni pizza is one of our most popular options. I'll make sure to get that started for you right away. Would you like it for delivery or pick-up? And would you like any sides or extras with that? For example, we have garlic knots, wings, salads, and various toppings that you can add to your pizza for an additional charge. Let me know if you have any preferences or if you'd like to add anything to your order. Once again, I'll be happy to help you with any questions or requests you might have.\n",
            "----------------------------------------\n",
            "USER: Delivery please.\n",
            "BOT :  Sure thing, Osamah! I'll make sure to get your large pepperoni pizza ready for delivery. May I have your address and contact number, please, so that our delivery driver can find you easily and contact you when they're on their way? Also, would you like to provide any special instructions for the delivery, such as a specific delivery location or any dietary restrictions for the driver to be aware of? I'll be happy to help you with any additional requests you might have. Once your pizza is ready, I'll give you a call to let you know and confirm the delivery details with you. In the meantime, if you have any questions or concerns, don't hesitate to ask. I'm here to make sure your experience at XYZ Pizza is a great one!\n",
            "----------------------------------------\n",
            "USER: My address is 123 Main Street and my phone is 555-0000.\n",
            "BOT :  Thank you for providing your address and phone number, Osamah. I'll make sure to pass that information along to our delivery driver. Your large pepperoni pizza will be ready soon, and I'll give you a call as soon as it's ready to confirm the delivery details with you and let you know approximately how long it will take for the driver to reach you. In the meantime, if you have any questions or concerns, don't hesitate to ask. I'm here to make sure your experience at XYZ Pizza is a great one! Is there anything else I can help you with while you wait for your pizza? For example, I can help you add sides or extras to your order, or answer any questions you might have about our menu or delivery process. Let me know if there's anything I can do to make your experience with us even better!\n",
            "----------------------------------------\n",
            "USER: Yes, that is everything.\n",
            "BOT :  Great, Osamah! I'll make sure to add your large pepperoni pizza to the delivery order with your address and phone number. If you have any questions or concerns before your pizza is ready, don't hesitate to ask. I'll be happy to help you with anything I can. Once your pizza is ready, I'll give you a call to confirm the delivery details and let you know approximately how long it will take for the driver to reach you. In the meantime, if you'd like to add any sides or extras to your order, just let me know and I'll be happy to help you with that. Otherwise, I'll see you soon with your delicious pizza! Enjoy your meal, and thank you for choosing XYZ Pizza for your delivery needs. Is there anything else I can help you with before we hang up?\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "example_res_b = run_scenario(llm_b, test_scenarios[0])\n",
        "for turn in example_res_b['transcript']:\n",
        "    print(\"USER:\", turn['user'])\n",
        "    print(\"BOT :\", turn['assistant'])\n",
        "    print(\"-\" * 40)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H4jmqn_7Gqqa",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H4jmqn_7Gqqa"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Interactive Chat Section\n",
        "# =========================\n",
        "\n",
        "def chat_with_model(llm, user_message):\n",
        "    \"\"\"One-shot chat: send a single message and get a reply.\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        "    reply = llm.chat(messages)\n",
        "    print(f\"{llm.name} BOT:\", reply)\n",
        "\n",
        "\n",
        "def chat_loop(llm):\n",
        "    \"\"\"Continuous chat loop. Type 'exit' to stop.\"\"\"\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
        "    print(f\"Start chatting with {llm.name}! Type 'exit' to stop.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user = input(\"You: \")\n",
        "        if user.lower().strip() in [\"exit\", \"quit\", \"stop\"]:\n",
        "            print(\"Chat ended.\")\n",
        "            break\n",
        "        messages.append({\"role\": \"user\", \"content\": user})\n",
        "        bot = llm.chat(messages)\n",
        "        messages.append({\"role\": \"assistant\", \"content\": bot})\n",
        "        print(f\"{llm.name} Bot:\", bot, \"\\n\")\n",
        "\n",
        "# Examples:\n",
        "# chat_with_model(llm_a, \"Hi, I want to order pizza.\")\n",
        "# chat_with_model(llm_b, \"Do you have vegetarian options?\")\n",
        "# chat_loop(llm_a)\n",
        "# chat_loop(llm_b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Oz_uAaUJGqxO",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Oz_uAaUJGqxO",
        "outputId": "751f879a-5a31-4dd9-9937-76443858af9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llama-2-7B-Chat BOT:   Great! Welcome to XYZ Pizza. My name is OrderBot, and I'll be taking your order today. Can I please have your name, please?\n"
          ]
        }
      ],
      "source": [
        "chat_with_model(llm_a, \"Hi, I want to order pizza.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0He2I3XsGq0w",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0He2I3XsGq0w"
      },
      "outputs": [],
      "source": [
        "import os, json\n",
        "from datetime import datetime\n",
        "\n",
        "# Folder to store chat logs\n",
        "LOG_DIR = \"chat_logs\"\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "def save_transcript(model_name, messages):\n",
        "    \"\"\"Save full chat messages to a timestamped txt + json file.\"\"\"\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    base = f\"{model_name}_{ts}\"\n",
        "\n",
        "    # Save as JSON (structured)\n",
        "    json_path = os.path.join(LOG_DIR, base + \".json\")\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(messages, f, indent=2)\n",
        "\n",
        "    # Save as TXT (human readable)\n",
        "    txt_path = os.path.join(LOG_DIR, base + \".txt\")\n",
        "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for m in messages:\n",
        "            f.write(f\"{m['role'].upper()}: {m['content']}\\n\\n\")\n",
        "\n",
        "    print(f\"‚úÖ Transcript saved:\\n- {txt_path}\\n- {json_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uv5PBCrnJP80",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uv5PBCrnJP80"
      },
      "outputs": [],
      "source": [
        "def chat_loop_with_logging(llm):\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
        "    print(f\"\\nüü¢ Chatting with {llm.name}. Type 'exit' to stop.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user = input(\"You: \")\n",
        "        if user.lower().strip() in [\"exit\", \"quit\", \"stop\"]:\n",
        "            print(\"Chat ended.\")\n",
        "            break\n",
        "\n",
        "        messages.append({\"role\": \"user\", \"content\": user})\n",
        "        bot = llm.chat(messages)\n",
        "        messages.append({\"role\": \"assistant\", \"content\": bot})\n",
        "        print(f\"{llm.name} Bot:\", bot, \"\\n\")\n",
        "\n",
        "    # auto-save at end\n",
        "    save_transcript(llm.name, messages)\n",
        "\n",
        "\n",
        "def choose_model_and_chat():\n",
        "    print(\"\\nChoose a model to chat with:\")\n",
        "    print(\"1) Model A (Llama-2-7B-Chat)\")\n",
        "    print(\"2) Model B (Mistral-7B-Instruct v0.2)\")\n",
        "\n",
        "    choice = input(\"Enter 1 or 2: \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        chat_loop_with_logging(llm_a)\n",
        "    elif choice == \"2\":\n",
        "        chat_loop_with_logging(llm_b)\n",
        "    else:\n",
        "        print(\"‚ùå Invalid choice. Run again and pick 1 or 2.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "spoA1I1QJP_m",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "spoA1I1QJP_m"
      },
      "outputs": [],
      "source": [
        "choose_model_and_chat()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "045f229853ff428b9188c47de072402f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d65da0cdbd4d47b351d2557d769353": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed4e8e8fd2874f79ae72829f3d55734d",
              "IPY_MODEL_f38200bb13454941ae984901ef0f8b2d",
              "IPY_MODEL_758161cdcb7c4ab083ee827bcae71b6e"
            ],
            "layout": "IPY_MODEL_ff8b5507f0594ae9a4b5101d6efdcd62",
            "tabbable": null,
            "tooltip": null
          }
        },
        "117075ac4e0343158afd7c4a354558e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_814f847baee74880a6e03076b7a3a845",
            "max": 4081004224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86cbee431aee469d8ad65f22fd276426",
            "tabbable": null,
            "tooltip": null,
            "value": 4081004224
          }
        },
        "2b2c5d4440324412ad2f69855f238086": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49ae8a83d76743999e220d6cb3f47cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2b2c5d4440324412ad2f69855f238086",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c096bcd5ac904577a91ebad1ccaa8297",
            "tabbable": null,
            "tooltip": null,
            "value": "‚Äá4.08G/4.08G‚Äá[00:35&lt;00:00,‚Äá84.0MB/s]"
          }
        },
        "4c9a8b1d4a75418c9dbeddc080157ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "52db477f1d924817b5367928014c434e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "758161cdcb7c4ab083ee827bcae71b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_aed38117fad94062b75a785338446c8a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4c9a8b1d4a75418c9dbeddc080157ea5",
            "tabbable": null,
            "tooltip": null,
            "value": "‚Äá4.37G/4.37G‚Äá[00:30&lt;00:00,‚Äá331MB/s]"
          }
        },
        "7b6d7ad13ffd443a92129b6b6dae6fab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8026efa8cd3341aabb2a0d0eca997630": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814f847baee74880a6e03076b7a3a845": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86cbee431aee469d8ad65f22fd276426": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f8f97f82ced4c5eb40fa53f8f20448f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "99b79a9f6acd4f53ac1d2c07d8522fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_045f229853ff428b9188c47de072402f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8f8f97f82ced4c5eb40fa53f8f20448f",
            "tabbable": null,
            "tooltip": null,
            "value": "llama-2-7b-chat.Q4_K_M.gguf:‚Äá100%"
          }
        },
        "aed38117fad94062b75a785338446c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c096bcd5ac904577a91ebad1ccaa8297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "ed4e8e8fd2874f79ae72829f3d55734d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ff9472ae86a5423f9276c4a0d1337ef0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f0eeb4d361c74d32b52370eef593461d",
            "tabbable": null,
            "tooltip": null,
            "value": "mistral-7b-instruct-v0.2.Q4_K_M.gguf:‚Äá100%"
          }
        },
        "f0eeb4d361c74d32b52370eef593461d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HTMLStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "f38200bb13454941ae984901ef0f8b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8026efa8cd3341aabb2a0d0eca997630",
            "max": 4368439584,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52db477f1d924817b5367928014c434e",
            "tabbable": null,
            "tooltip": null,
            "value": 4368439584
          }
        },
        "fdf9dbee54d54eb3bc0350524505752a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "2.0.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99b79a9f6acd4f53ac1d2c07d8522fc3",
              "IPY_MODEL_117075ac4e0343158afd7c4a354558e3",
              "IPY_MODEL_49ae8a83d76743999e220d6cb3f47cb7"
            ],
            "layout": "IPY_MODEL_7b6d7ad13ffd443a92129b6b6dae6fab",
            "tabbable": null,
            "tooltip": null
          }
        },
        "ff8b5507f0594ae9a4b5101d6efdcd62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff9472ae86a5423f9276c4a0d1337ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "2.0.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}